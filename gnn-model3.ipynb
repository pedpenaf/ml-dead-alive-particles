{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import Voronoi\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful functions\n",
    "\n",
    "def create_ffn(hidden_units, dropout_rate, input_shape=None, name=None):\n",
    "    \n",
    "    #Creates a sequential model (feed-forward network) \n",
    "   \n",
    "    fnn_layers = []\n",
    "    if input_shape is not None:\n",
    "        fnn_layers.append(layers.Input(shape=input_shape))\n",
    "    for units in hidden_units:\n",
    "        fnn_layers.append(layers.BatchNormalization())\n",
    "        fnn_layers.append(layers.Dropout(dropout_rate))\n",
    "        fnn_layers.append(layers.Dense(units, activation=tf.nn.gelu))\n",
    "    return keras.Sequential(fnn_layers, name=name)\n",
    "\n",
    "def create_gru(hidden_units, dropout_rate):\n",
    "    \n",
    "    #Creates a GRU based model for combining nodes information\n",
    "    \n",
    "    inputs = keras.layers.Input(shape=(2, hidden_units[0]))\n",
    "    x = inputs\n",
    "    for units in hidden_units:\n",
    "        x = layers.GRU(\n",
    "            units=units,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            return_sequences=True,\n",
    "            dropout=dropout_rate,\n",
    "            recurrent_dropout=dropout_rate\n",
    "        )(x)\n",
    "    return keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "#Convolution layer\n",
    "\n",
    "class GraphConvLayer(layers.Layer):\n",
    "    def __init__(self, hidden_units, dropout_rate=0.2, aggregation_type=\"mean\",\n",
    "                 combination_type=\"concat\", normalize=False, *args, **kwargs):\n",
    "\n",
    "        # Layer that processes messages in a graph: prepares messages from neighbours with a FFN, \n",
    "        # aggregates messages of neighbours through a specified method (sum,mean,max) and combines \n",
    "        # the node representation with the aggregated message\n",
    "\n",
    "        super(GraphConvLayer, self).__init__(*args, **kwargs)\n",
    "        self.aggregation_type = aggregation_type\n",
    "        self.combination_type = combination_type\n",
    "        self.normalize = normalize\n",
    "        self.hidden_units = hidden_units\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # FFN para preparar mensajes\n",
    "        self.ffn_prepare = create_ffn(hidden_units, dropout_rate, name=\"ffn_prepare\")\n",
    "        # Función de actualización: puede ser una GRU o una FFN\n",
    "        if self.combination_type == \"gru\":\n",
    "            self.update_fn = create_gru(hidden_units, dropout_rate)\n",
    "        else:\n",
    "            self.update_fn = create_ffn(hidden_units, dropout_rate, name=\"update_ffn\")\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        #We can implement the variable initialization here if necessary \n",
    "        super(GraphConvLayer, self).build(input_shape)\n",
    "\n",
    "    def prepare(self, node_representations, weights=None):\n",
    "        messages = self.ffn_prepare(node_representations)\n",
    "        if weights is not None:\n",
    "            messages = messages * tf.expand_dims(weights, -1)\n",
    "        return messages\n",
    "\n",
    "    def aggregate(self, node_indices, neighbour_messages, node_representations):\n",
    "        # As it can vary between images, we use the number of nodes dinamically\n",
    "        # node_indices shape is [num_edges].\n",
    "        # neighbour_messages shape: [num_edges, representation_dim].\n",
    "        # node_repesentations shape is [num_nodes, representation_dim]\n",
    "        num_nodes = tf.shape(node_representations)[0]\n",
    "        if self.aggregation_type == \"sum\":\n",
    "            aggregated_message = tf.math.unsorted_segment_sum(neighbour_messages, node_indices, num_segments=num_nodes)\n",
    "        elif self.aggregation_type == \"mean\":\n",
    "            aggregated_message = tf.math.unsorted_segment_mean(neighbour_messages, node_indices, num_segments=num_nodes)\n",
    "        elif self.aggregation_type == \"max\":\n",
    "            aggregated_message = tf.math.unsorted_segment_max(neighbour_messages, node_indices, num_segments=num_nodes)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid aggregation type: {self.aggregation_type}.\")\n",
    "        return aggregated_message\n",
    "\n",
    "    def update(self, node_representations, aggregated_messages):\n",
    "        # node_repesentations shape is [num_nodes, representation_dim].\n",
    "        # aggregated_messages shape is [num_nodes, representation_dim].\n",
    "        if self.combination_type == \"gru\":\n",
    "            h = tf.stack([node_representations, aggregated_messages], axis=1)\n",
    "        elif self.combination_type == \"concat\":\n",
    "            h = tf.concat([node_representations, aggregated_messages], axis=1)\n",
    "        elif self.combination_type == \"add\":\n",
    "            h = node_representations + aggregated_messages\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid combination type: {self.combination_type}.\")\n",
    "        node_embeddings = self.update_fn(h)\n",
    "        if self.combination_type == \"gru\":\n",
    "            # Seleccionamos la salida final de la secuencia GRU\n",
    "            node_embeddings = tf.unstack(node_embeddings, axis=1)[-1]\n",
    "        if self.normalize:\n",
    "            node_embeddings = tf.nn.l2_normalize(node_embeddings, axis=-1)\n",
    "        return node_embeddings\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Process the inputs to produce the node_embeddings.\n",
    "\n",
    "        inputs: a tuple of three elements: node_repesentations, edges, edge_weights.\n",
    "            -node_representations: tensor with shape (num_nodes,feature_dim)\n",
    "            -edges: tensor with shape (num_edges,2) \n",
    "            -edge_weights:with shape (num_edges,), as in our problem all the edges\n",
    "            have the same weight this tensor is going to be a ones array\n",
    "        Returns: node_embeddings of shape [num_nodes, representation_dim].\n",
    "        \"\"\"\n",
    "        node_representations, edges, edge_weights = inputs\n",
    "        # Divide the source and target indices\n",
    "        source_indexes = edges[:, 0]\n",
    "        target_indexes = edges[:, 1]\n",
    "        # Obtain the neighbour (target) representations\n",
    "        neighbour_representations = tf.gather(node_representations, target_indexes)\n",
    "        neighbour_messages = self.prepare(neighbour_representations, edge_weights)\n",
    "        aggregated_messages = self.aggregate(source_indexes, neighbour_messages, node_representations)\n",
    "        return self.update(node_representations, aggregated_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Node Classifier model \n",
    "\n",
    "class GNNNodeClassifier(tf.keras.Model):\n",
    "    def __init__(self, num_classes, hidden_units, aggregation_type=\"mean\",\n",
    "                 combination_type=\"concat\", dropout_rate=0.2, normalize=True, *args, **kwargs):\n",
    "        super(GNNNodeClassifier, self).__init__(*args, **kwargs)\n",
    "        # Preprocessing: transform the node features\n",
    "        self.preprocess = create_ffn(hidden_units, dropout_rate, name=\"preprocess\")\n",
    "        # Convolutional layers\n",
    "        self.conv1 = GraphConvLayer(hidden_units, dropout_rate, aggregation_type,\n",
    "                                    combination_type, normalize, name=\"graph_conv1\")\n",
    "        self.conv2 = GraphConvLayer(hidden_units, dropout_rate, aggregation_type,\n",
    "                                    combination_type, normalize, name=\"graph_conv2\")\n",
    "        # Postprocessing\n",
    "        self.postprocess = create_ffn(hidden_units, dropout_rate, name=\"postprocess\")\n",
    "        # Final layer that produces the logits for each node\n",
    "        self.compute_logits = layers.Dense(units=num_classes, name=\"logits\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Inputs should be a tuple of:\n",
    "        (node_features, edges, edge_weights, input_node_indices)\n",
    "        where:\n",
    "            - node_features: tensor with shape (batch_size, num_nodes, feature_dim)\n",
    "            - edges: tensor with shape (batch_size, num_edges, 2)\n",
    "            - edge_weights: tensor with shape (batch_size, num_edges)\n",
    "            - node_indices: tensor with shape (batch_size, num_nodes)\n",
    "        Each input corresponds to a graph/image\n",
    "\n",
    "        \"\"\"\n",
    "        node_features, edges, edge_weights, node_indices = inputs\n",
    "\n",
    "        # Function that processes a single graph\n",
    "        def process_graph(single_inputs):\n",
    "            nf, e, ew, ni = single_inputs  # nf: (num_nodes, feature_dim), e: (num_edges, 2), etc.\n",
    "            x = self.preprocess(nf)  # x: (num_nodes, hidden_dim)\n",
    "            x1 = self.conv1((x, e, ew))\n",
    "            x = x + x1  \n",
    "            x2 = self.conv2((x, e, ew))\n",
    "            x = x + x2  \n",
    "            x = self.postprocess(x)\n",
    "            # Obtain the representations for each node\n",
    "            node_emb = tf.gather(x, ni)\n",
    "            logits = self.compute_logits(node_emb)  # (num_nodes, num_classes)\n",
    "            return logits\n",
    "\n",
    "        # Apply tf.map_fn for processing each graph of the batch\n",
    "        outputs = tf.map_fn(process_graph, (node_features, edges, edge_weights, node_indices),\n",
    "                            fn_output_signature=tf.float32)\n",
    "        # outputs have shape:(batch_size, num_nodes, num_classes)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for extracting data from the dataframe and building the dataset\n",
    "def extract_graph_data(df, image_id):\n",
    "    \"\"\"\n",
    "    Extracts data of the graph for a given image\n",
    "      - Filters the rows with image_id.\n",
    "      - Uses columns 'x' and 'y' por Voronoi tessellation\n",
    "      - Extracts features for each node \n",
    "      - Label is the column 'activity'\n",
    "    \"\"\"\n",
    "    df_img = df[df['image_id'] == image_id].reset_index(drop=True)\n",
    "    num_nodes = df_img.shape[0]\n",
    "    \n",
    "    points = df_img[['x', 'y']].to_numpy()\n",
    "    vor = Voronoi(points)\n",
    "    # Obtains the edges (a pair of points) for the Voronoi tessellation\n",
    "    if len(vor.ridge_points) > 0:\n",
    "        edges = np.array(vor.ridge_points, dtype=np.int32)\n",
    "    else:\n",
    "        edges = np.empty((0, 2), dtype=np.int32)\n",
    "    num_edges = edges.shape[0]\n",
    "   \n",
    "    edge_weights = np.ones((num_edges,), dtype=np.float32)\n",
    "       \n",
    "    feature_cols = [col for col in df_img.columns if col not in ['image_id', 'activity','label','type']]\n",
    "    node_features = df_img[feature_cols].to_numpy().astype(np.float32)\n",
    "\n",
    "    labels = df_img['activity'].to_numpy().astype(np.int32)\n",
    "    # Modes indexes: just from 0 to num_nodes-1\n",
    "    node_indexes = np.arange(num_nodes, dtype=np.int32)\n",
    "    \n",
    "    return node_features, edges, edge_weights, node_indexes, labels\n",
    "\n",
    "#Creates a tf.data.Dataset from a dataframe\n",
    "def create_graph_dataset(df, batch_size, feature_dim):\n",
    "    image_ids = df['image_id'].unique()\n",
    "    \n",
    "    def gen():\n",
    "        for img_id in image_ids:\n",
    "            node_features, edges, edge_weights, node_indices, labels = extract_graph_data(df, img_id)\n",
    "            # Ensure that the shapes are correct:\n",
    "            node_features = np.reshape(node_features, (-1, feature_dim))\n",
    "            # edges with shape:(num_edges, 2)\n",
    "            edges = np.reshape(edges, (-1, 2))\n",
    "            edge_weights = np.reshape(edge_weights, (-1,))\n",
    "            node_indices = np.reshape(node_indices, (-1,))\n",
    "            labels = np.reshape(labels, (-1,))\n",
    "            yield (node_features, edges, edge_weights, node_indices), labels\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_signature=(\n",
    "            (\n",
    "                tf.TensorSpec(shape=(None, feature_dim), dtype=tf.float32),  # node_features\n",
    "                tf.TensorSpec(shape=(None, 2), dtype=tf.int32),              # edges\n",
    "                tf.TensorSpec(shape=(None,), dtype=tf.float32),              # edge_weights\n",
    "                tf.TensorSpec(shape=(None,), dtype=tf.int32),                # node_indices\n",
    "            ),\n",
    "            tf.TensorSpec(shape=(None,), dtype=tf.int32)  # labels\n",
    "        )\n",
    "    )\n",
    "    # Use padded_batch para handling graphs with a varying number of edges\n",
    "    dataset = dataset.padded_batch(\n",
    "        batch_size,\n",
    "        padded_shapes=(\n",
    "            (\n",
    "                tf.TensorShape([None, feature_dim]),  # node_features\n",
    "                tf.TensorShape([None, 2]),              # edges\n",
    "                tf.TensorShape([None]),                # edge_weights\n",
    "                tf.TensorShape([None]),                # node_indices\n",
    "            ),\n",
    "            tf.TensorShape([None])  # labels\n",
    "        ),\n",
    "        padding_values=(\n",
    "            (\n",
    "                tf.constant(0, dtype=tf.float32),\n",
    "                tf.constant(0, dtype=tf.int32),\n",
    "                tf.constant(0, dtype=tf.float32),\n",
    "                tf.constant(0, dtype=tf.int32),\n",
    "            ),\n",
    "            tf.constant(-1, dtype=tf.int32)\n",
    "        )\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the input data\n",
    "density=0.008\n",
    "fa=100\n",
    "input_file=f'phia{density}/traj_phia{density}-T05-Fa{fa}-tau1.dat'\n",
    "df=pd.read_csv(input_file, sep='\\s+',names=[\"label\", \"type\", \"x\", \"y\"])\n",
    "cols_names=['area', 'perimeter', 'neighbours', 'max neighbour distance',\n",
    "       'min neighbour distance', 'max vertices distance',\n",
    "       'min vertices distance', 'max vertices-point distance',\n",
    "       'min vertices-point distance', 'distance to center', 'activity',\n",
    "       'particle type']\n",
    "input_file2=f\"phia{density}/particles-features-{density}-Fa{fa}.txt\"\n",
    "df2=pd.read_csv(input_file2, sep='\\s+',names=cols_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create a dataframe that includes both, the voronoi features and the particle positions\n",
    "df=df[0:2_000_000].join(df2[['activity','particle type']])\n",
    "df['image_id']=np.floor(df.index/1000) #Add a column with the id of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>max neighbour distance</th>\n",
       "      <th>min neighbour distance</th>\n",
       "      <th>max vertices distance</th>\n",
       "      <th>min vertices distance</th>\n",
       "      <th>max vertices-point distance</th>\n",
       "      <th>min vertices-point distance</th>\n",
       "      <th>distance to center</th>\n",
       "      <th>activity</th>\n",
       "      <th>particle type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.509048</td>\n",
       "      <td>4.619494</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.389780</td>\n",
       "      <td>0.806291</td>\n",
       "      <td>1.749777</td>\n",
       "      <td>0.094486</td>\n",
       "      <td>1.208872</td>\n",
       "      <td>0.544046</td>\n",
       "      <td>0.314895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.906746</td>\n",
       "      <td>3.560549</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.344067</td>\n",
       "      <td>0.849852</td>\n",
       "      <td>1.254054</td>\n",
       "      <td>0.290809</td>\n",
       "      <td>0.701256</td>\n",
       "      <td>0.522356</td>\n",
       "      <td>0.070095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.133446</td>\n",
       "      <td>4.360792</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.515713</td>\n",
       "      <td>0.747911</td>\n",
       "      <td>1.773958</td>\n",
       "      <td>0.166268</td>\n",
       "      <td>1.066246</td>\n",
       "      <td>0.550184</td>\n",
       "      <td>0.182413</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.188564</td>\n",
       "      <td>4.386444</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.534631</td>\n",
       "      <td>0.940811</td>\n",
       "      <td>1.706916</td>\n",
       "      <td>0.133938</td>\n",
       "      <td>1.121070</td>\n",
       "      <td>0.593270</td>\n",
       "      <td>0.165394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.957859</td>\n",
       "      <td>3.801955</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.344167</td>\n",
       "      <td>0.773250</td>\n",
       "      <td>1.333893</td>\n",
       "      <td>0.613972</td>\n",
       "      <td>0.794984</td>\n",
       "      <td>0.518038</td>\n",
       "      <td>0.109953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999995</th>\n",
       "      <td>0.728351</td>\n",
       "      <td>3.266792</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.940885</td>\n",
       "      <td>0.859831</td>\n",
       "      <td>1.115772</td>\n",
       "      <td>0.508507</td>\n",
       "      <td>0.588221</td>\n",
       "      <td>0.528581</td>\n",
       "      <td>0.008838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999996</th>\n",
       "      <td>0.734543</td>\n",
       "      <td>3.263756</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.150930</td>\n",
       "      <td>0.839641</td>\n",
       "      <td>1.116880</td>\n",
       "      <td>0.175863</td>\n",
       "      <td>0.599798</td>\n",
       "      <td>0.506478</td>\n",
       "      <td>0.021165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999997</th>\n",
       "      <td>0.724906</td>\n",
       "      <td>3.265421</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.039930</td>\n",
       "      <td>0.826719</td>\n",
       "      <td>1.123328</td>\n",
       "      <td>0.547255</td>\n",
       "      <td>0.590320</td>\n",
       "      <td>0.519502</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999998</th>\n",
       "      <td>0.928878</td>\n",
       "      <td>3.623905</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.185654</td>\n",
       "      <td>0.839641</td>\n",
       "      <td>1.268073</td>\n",
       "      <td>0.461185</td>\n",
       "      <td>0.703500</td>\n",
       "      <td>0.531562</td>\n",
       "      <td>0.085175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999999</th>\n",
       "      <td>0.859530</td>\n",
       "      <td>3.471872</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.156001</td>\n",
       "      <td>0.876244</td>\n",
       "      <td>1.190321</td>\n",
       "      <td>0.356996</td>\n",
       "      <td>0.664689</td>\n",
       "      <td>0.520248</td>\n",
       "      <td>0.075781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             area  perimeter  neighbours  max neighbour distance  \\\n",
       "0        1.509048   4.619494         8.0                2.389780   \n",
       "1        0.906746   3.560549         7.0                1.344067   \n",
       "2        1.133446   4.360792         5.0                1.515713   \n",
       "3        1.188564   4.386444         6.0                1.534631   \n",
       "4        0.957859   3.801955         5.0                1.344167   \n",
       "...           ...        ...         ...                     ...   \n",
       "1999995  0.728351   3.266792         5.0                0.940885   \n",
       "1999996  0.734543   3.263756         6.0                1.150930   \n",
       "1999997  0.724906   3.265421         5.0                1.039930   \n",
       "1999998  0.928878   3.623905         6.0                1.185654   \n",
       "1999999  0.859530   3.471872         6.0                1.156001   \n",
       "\n",
       "         min neighbour distance  max vertices distance  min vertices distance  \\\n",
       "0                      0.806291               1.749777               0.094486   \n",
       "1                      0.849852               1.254054               0.290809   \n",
       "2                      0.747911               1.773958               0.166268   \n",
       "3                      0.940811               1.706916               0.133938   \n",
       "4                      0.773250               1.333893               0.613972   \n",
       "...                         ...                    ...                    ...   \n",
       "1999995                0.859831               1.115772               0.508507   \n",
       "1999996                0.839641               1.116880               0.175863   \n",
       "1999997                0.826719               1.123328               0.547255   \n",
       "1999998                0.839641               1.268073               0.461185   \n",
       "1999999                0.876244               1.190321               0.356996   \n",
       "\n",
       "         max vertices-point distance  min vertices-point distance  \\\n",
       "0                           1.208872                     0.544046   \n",
       "1                           0.701256                     0.522356   \n",
       "2                           1.066246                     0.550184   \n",
       "3                           1.121070                     0.593270   \n",
       "4                           0.794984                     0.518038   \n",
       "...                              ...                          ...   \n",
       "1999995                     0.588221                     0.528581   \n",
       "1999996                     0.599798                     0.506478   \n",
       "1999997                     0.590320                     0.519502   \n",
       "1999998                     0.703500                     0.531562   \n",
       "1999999                     0.664689                     0.520248   \n",
       "\n",
       "         distance to center  activity  particle type  \n",
       "0                  0.314895       1.0            1.0  \n",
       "1                  0.070095       1.0            1.0  \n",
       "2                  0.182413       1.0            1.0  \n",
       "3                  0.165394       1.0            1.0  \n",
       "4                  0.109953       1.0            1.0  \n",
       "...                     ...       ...            ...  \n",
       "1999995            0.008838       0.0            0.0  \n",
       "1999996            0.021165       0.0            0.0  \n",
       "1999997            0.023943       0.0            0.0  \n",
       "1999998            0.085175       0.0            1.0  \n",
       "1999999            0.075781       0.0            1.0  \n",
       "\n",
       "[2000000 rows x 12 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>activity</th>\n",
       "      <th>particle type</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.043000</td>\n",
       "      <td>13.01330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.042000</td>\n",
       "      <td>3.42631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8.108120</td>\n",
       "      <td>1.22057</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13.972700</td>\n",
       "      <td>15.03460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>27.316800</td>\n",
       "      <td>27.18760</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999995</th>\n",
       "      <td>996</td>\n",
       "      <td>4</td>\n",
       "      <td>26.649500</td>\n",
       "      <td>24.25770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999996</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>2.654000</td>\n",
       "      <td>8.21493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999997</th>\n",
       "      <td>998</td>\n",
       "      <td>4</td>\n",
       "      <td>5.972230</td>\n",
       "      <td>11.16460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999998</th>\n",
       "      <td>999</td>\n",
       "      <td>4</td>\n",
       "      <td>0.579158</td>\n",
       "      <td>19.03150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999999</th>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.272200</td>\n",
       "      <td>25.00370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label  type          x         y  activity  particle type  image_id\n",
       "0            1     1  13.043000  13.01330       1.0            1.0       0.0\n",
       "1            2     1   9.042000   3.42631       1.0            1.0       0.0\n",
       "2            3     1   8.108120   1.22057       1.0            1.0       0.0\n",
       "3            4     1  13.972700  15.03460       1.0            1.0       0.0\n",
       "4            5     1  27.316800  27.18760       1.0            1.0       0.0\n",
       "...        ...   ...        ...       ...       ...            ...       ...\n",
       "1999995    996     4  26.649500  24.25770       0.0            0.0    1999.0\n",
       "1999996    997     4   2.654000   8.21493       0.0            0.0    1999.0\n",
       "1999997    998     4   5.972230  11.16460       0.0            0.0    1999.0\n",
       "1999998    999     4   0.579158  19.03150       0.0            1.0    1999.0\n",
       "1999999   1000     4   3.272200  25.00370       0.0            1.0    1999.0\n",
       "\n",
       "[2000000 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score,roc_auc_score\n",
    "feature_cols = [col for col in df.columns if col not in ['image_id', 'activity','label','type']]\n",
    "feature_dim = len(feature_cols)\n",
    "\n",
    "# Model parameters\n",
    "num_classes = 2       \n",
    "hidden_units = [64, 64]\n",
    "dropout_rate = 0.2\n",
    "aggregation_type = \"mean\"\n",
    "combination_type = \"concat\"\n",
    "normalize = True\n",
    "batch_size = 1  \n",
    "\n",
    "images_ids=df['image_id'].unique()\n",
    "train_images_ids,test_images_ids=train_test_split(images_ids,random_state=50,test_size=0.2)\n",
    "train_df=df[df['image_id'].isin(train_images_ids)].reset_index(drop=True)\n",
    "test_df=df[df['image_id'].isin(test_images_ids)].reset_index(drop=True)\n",
    "\n",
    "# Create training and testing datasets\n",
    "train_dataset = create_graph_dataset(train_df, batch_size, feature_dim)\n",
    "test_dataset = create_graph_dataset(test_df, batch_size, feature_dim)\n",
    "def one_hot_map_fn(inputs, labels):\n",
    "    # Convert labels from shape (batch_size, num_particles) to (batch_size, num_particles, 2)\n",
    "    one_hot_labels = tf.one_hot(labels, depth=2)\n",
    "    return inputs, one_hot_labels\n",
    "\n",
    "train_dataset = train_dataset.map(one_hot_map_fn)\n",
    "test_dataset = test_dataset.map(one_hot_map_fn)\n",
    "\n",
    "# Instance and compile the GNN model\n",
    "model = GNNNodeClassifier(num_classes, hidden_units, aggregation_type, combination_type, dropout_rate, normalize)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalFocalCrossentropy(alpha=0.25,gamma=4,from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 16ms/step - accuracy: 0.9900 - loss: 0.0014\n",
      "Epoch 2/10\n",
      "\u001b[1m   9/1600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9920 - loss: 0.0012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9920 - loss: 0.0012\n",
      "Epoch 3/10\n",
      "\u001b[1m   9/1600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9920 - loss: 0.0011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9920 - loss: 0.0012\n",
      "Epoch 4/10\n",
      "\u001b[1m   9/1600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.9920 - loss: 0.0011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9920 - loss: 0.0011\n",
      "Epoch 5/10\n",
      "\u001b[1m   9/1600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.9920 - loss: 0.0011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 819/1600\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9920 - loss: 0.0011"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(train_dataset,['image_id', 'activity','label','type'] epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8121 - loss: 0.0075\n",
      "0.8119399547576904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "accuracy=model.evaluate(test_dataset)\n",
    "print(accuracy[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "for (node_features, edges, edge_weights, node_indices), labels in test_dataset:\n",
    "    predictions = model((node_features, edges, edge_weights, node_indices))\n",
    "    probabilities = keras.activations.softmax(tf.convert_to_tensor(predictions)).numpy()\n",
    "\n",
    "    decision=np.floor(probabilities[:,:,1]*2)\n",
    "    labels=np.floor(labels[:,:,1])\n",
    "    all_labels.extend(labels.flatten())\n",
    "    all_predictions.extend(decision.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.5512062499999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.99      0.89    320000\n",
      "         1.0       0.67      0.12      0.20     80000\n",
      "\n",
      "    accuracy                           0.81    400000\n",
      "   macro avg       0.74      0.55      0.55    400000\n",
      "weighted avg       0.79      0.81      0.75    400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,classification_report\n",
    "\n",
    "auc = roc_auc_score(all_labels, all_predictions)\n",
    "# f1= f1_score(all_labels,all_predictions)\n",
    "print(\"Test AUC:\", auc)\n",
    "# print('Test F1:',f1)\n",
    "print(classification_report(all_labels,all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 400000\n"
     ]
    }
   ],
   "source": [
    "print(len(all_predictions),len(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>max neighbour distance</th>\n",
       "      <th>min neighbour distance</th>\n",
       "      <th>max vertices distance</th>\n",
       "      <th>min vertices distance</th>\n",
       "      <th>max vertices-point distance</th>\n",
       "      <th>min vertices-point distance</th>\n",
       "      <th>distance to center</th>\n",
       "      <th>activity</th>\n",
       "      <th>particle type</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.71810</td>\n",
       "      <td>3.963970</td>\n",
       "      <td>0.992258</td>\n",
       "      <td>3.836169</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.756655</td>\n",
       "      <td>0.822074</td>\n",
       "      <td>1.436207</td>\n",
       "      <td>0.015668</td>\n",
       "      <td>0.884407</td>\n",
       "      <td>0.509452</td>\n",
       "      <td>0.129601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.83950</td>\n",
       "      <td>28.755500</td>\n",
       "      <td>1.222737</td>\n",
       "      <td>4.237809</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.405774</td>\n",
       "      <td>1.081656</td>\n",
       "      <td>1.501896</td>\n",
       "      <td>0.201827</td>\n",
       "      <td>0.794314</td>\n",
       "      <td>0.651656</td>\n",
       "      <td>0.021338</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14.11380</td>\n",
       "      <td>0.123613</td>\n",
       "      <td>1.021340</td>\n",
       "      <td>3.896370</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.549040</td>\n",
       "      <td>0.911955</td>\n",
       "      <td>1.440380</td>\n",
       "      <td>0.250894</td>\n",
       "      <td>0.854049</td>\n",
       "      <td>0.552541</td>\n",
       "      <td>0.084406</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>27.99440</td>\n",
       "      <td>27.836500</td>\n",
       "      <td>0.996716</td>\n",
       "      <td>3.825848</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.444316</td>\n",
       "      <td>0.855382</td>\n",
       "      <td>1.407457</td>\n",
       "      <td>0.115618</td>\n",
       "      <td>0.733849</td>\n",
       "      <td>0.540194</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20.58560</td>\n",
       "      <td>16.870600</td>\n",
       "      <td>0.861796</td>\n",
       "      <td>3.562893</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.212920</td>\n",
       "      <td>0.901367</td>\n",
       "      <td>1.226116</td>\n",
       "      <td>0.105015</td>\n",
       "      <td>0.700601</td>\n",
       "      <td>0.527187</td>\n",
       "      <td>0.036320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>996</td>\n",
       "      <td>4</td>\n",
       "      <td>17.00900</td>\n",
       "      <td>16.738400</td>\n",
       "      <td>1.398074</td>\n",
       "      <td>4.562085</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.706074</td>\n",
       "      <td>1.043705</td>\n",
       "      <td>1.564971</td>\n",
       "      <td>0.018557</td>\n",
       "      <td>0.901003</td>\n",
       "      <td>0.571301</td>\n",
       "      <td>0.128033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>27.12020</td>\n",
       "      <td>3.015330</td>\n",
       "      <td>0.644134</td>\n",
       "      <td>3.089516</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.205705</td>\n",
       "      <td>0.792358</td>\n",
       "      <td>1.066991</td>\n",
       "      <td>0.024285</td>\n",
       "      <td>0.604872</td>\n",
       "      <td>0.476485</td>\n",
       "      <td>0.031195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>998</td>\n",
       "      <td>4</td>\n",
       "      <td>28.79020</td>\n",
       "      <td>6.405500</td>\n",
       "      <td>0.777852</td>\n",
       "      <td>3.426046</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.183314</td>\n",
       "      <td>0.789633</td>\n",
       "      <td>1.177903</td>\n",
       "      <td>0.128303</td>\n",
       "      <td>0.631295</td>\n",
       "      <td>0.570359</td>\n",
       "      <td>0.036724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>999</td>\n",
       "      <td>4</td>\n",
       "      <td>11.37550</td>\n",
       "      <td>25.538700</td>\n",
       "      <td>0.648328</td>\n",
       "      <td>3.096628</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.859703</td>\n",
       "      <td>0.801224</td>\n",
       "      <td>1.098747</td>\n",
       "      <td>0.505184</td>\n",
       "      <td>0.608810</td>\n",
       "      <td>0.491049</td>\n",
       "      <td>0.020731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>9.69861</td>\n",
       "      <td>7.494090</td>\n",
       "      <td>0.721191</td>\n",
       "      <td>3.184995</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.036786</td>\n",
       "      <td>0.839039</td>\n",
       "      <td>1.120351</td>\n",
       "      <td>0.395579</td>\n",
       "      <td>0.567975</td>\n",
       "      <td>0.479669</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label  type         x          y      area  perimeter  neighbours  \\\n",
       "0            1     1   8.71810   3.963970  0.992258   3.836169         8.0   \n",
       "1            2     1  19.83950  28.755500  1.222737   4.237809         6.0   \n",
       "2            3     1  14.11380   0.123613  1.021340   3.896370         6.0   \n",
       "3            4     1  27.99440  27.836500  0.996716   3.825848         6.0   \n",
       "4            5     1  20.58560  16.870600  0.861796   3.562893         6.0   \n",
       "...        ...   ...       ...        ...       ...        ...         ...   \n",
       "1599995    996     4  17.00900  16.738400  1.398074   4.562085         6.0   \n",
       "1599996    997     4  27.12020   3.015330  0.644134   3.089516         6.0   \n",
       "1599997    998     4  28.79020   6.405500  0.777852   3.426046         6.0   \n",
       "1599998    999     4  11.37550  25.538700  0.648328   3.096628         5.0   \n",
       "1599999   1000     4   9.69861   7.494090  0.721191   3.184995         6.0   \n",
       "\n",
       "         max neighbour distance  min neighbour distance  \\\n",
       "0                      1.756655                0.822074   \n",
       "1                      1.405774                1.081656   \n",
       "2                      1.549040                0.911955   \n",
       "3                      1.444316                0.855382   \n",
       "4                      1.212920                0.901367   \n",
       "...                         ...                     ...   \n",
       "1599995                1.706074                1.043705   \n",
       "1599996                1.205705                0.792358   \n",
       "1599997                1.183314                0.789633   \n",
       "1599998                0.859703                0.801224   \n",
       "1599999                1.036786                0.839039   \n",
       "\n",
       "         max vertices distance  min vertices distance  \\\n",
       "0                     1.436207               0.015668   \n",
       "1                     1.501896               0.201827   \n",
       "2                     1.440380               0.250894   \n",
       "3                     1.407457               0.115618   \n",
       "4                     1.226116               0.105015   \n",
       "...                        ...                    ...   \n",
       "1599995               1.564971               0.018557   \n",
       "1599996               1.066991               0.024285   \n",
       "1599997               1.177903               0.128303   \n",
       "1599998               1.098747               0.505184   \n",
       "1599999               1.120351               0.395579   \n",
       "\n",
       "         max vertices-point distance  min vertices-point distance  \\\n",
       "0                           0.884407                     0.509452   \n",
       "1                           0.794314                     0.651656   \n",
       "2                           0.854049                     0.552541   \n",
       "3                           0.733849                     0.540194   \n",
       "4                           0.700601                     0.527187   \n",
       "...                              ...                          ...   \n",
       "1599995                     0.901003                     0.571301   \n",
       "1599996                     0.604872                     0.476485   \n",
       "1599997                     0.631295                     0.570359   \n",
       "1599998                     0.608810                     0.491049   \n",
       "1599999                     0.567975                     0.479669   \n",
       "\n",
       "         distance to center  activity  particle type  image_id  \n",
       "0                  0.129601       1.0            1.0       0.0  \n",
       "1                  0.021338       1.0            1.0       0.0  \n",
       "2                  0.084406       1.0            1.0       0.0  \n",
       "3                  0.057512       1.0            1.0       0.0  \n",
       "4                  0.036320       1.0            1.0       0.0  \n",
       "...                     ...       ...            ...       ...  \n",
       "1599995            0.128033       0.0            0.0    1999.0  \n",
       "1599996            0.031195       0.0            0.0    1999.0  \n",
       "1599997            0.036724       0.0            0.0    1999.0  \n",
       "1599998            0.020731       0.0            0.0    1999.0  \n",
       "1599999            0.018331       0.0            0.0    1999.0  \n",
       "\n",
       "[1600000 rows x 17 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
