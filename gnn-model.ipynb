{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import Voronoi\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful functions\n",
    "\n",
    "def create_ffn(hidden_units, dropout_rate, input_shape=None, name=None):\n",
    "    \n",
    "    #Creates a sequential model (feed-forward network) \n",
    "   \n",
    "    fnn_layers = []\n",
    "    if input_shape is not None:\n",
    "        fnn_layers.append(layers.Input(shape=input_shape))\n",
    "    for units in hidden_units:\n",
    "        fnn_layers.append(layers.BatchNormalization())\n",
    "        fnn_layers.append(layers.Dropout(dropout_rate))\n",
    "        fnn_layers.append(layers.Dense(units, activation=tf.nn.gelu))\n",
    "    return keras.Sequential(fnn_layers, name=name)\n",
    "\n",
    "def create_gru(hidden_units, dropout_rate):\n",
    "    \n",
    "    #Creates a GRU based model for combining nodes information\n",
    "    \n",
    "    inputs = keras.layers.Input(shape=(2, hidden_units[0]))\n",
    "    x = inputs\n",
    "    for units in hidden_units:\n",
    "        x = layers.GRU(\n",
    "            units=units,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            return_sequences=True,\n",
    "            dropout=dropout_rate,\n",
    "            recurrent_dropout=dropout_rate\n",
    "        )(x)\n",
    "    return keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "#Convolution layer\n",
    "\n",
    "class GraphConvLayer(layers.Layer):\n",
    "    def __init__(self, hidden_units, dropout_rate=0.2, aggregation_type=\"mean\",\n",
    "                 combination_type=\"concat\", normalize=False, *args, **kwargs):\n",
    "\n",
    "        # Layer that processes messages in a graph: prepares messages from neighbours with a FFN, \n",
    "        # aggregates messages of neighbours through a specified method (sum,mean,max) and combines \n",
    "        # the node representation with the aggregated message\n",
    "\n",
    "        super(GraphConvLayer, self).__init__(*args, **kwargs)\n",
    "        self.aggregation_type = aggregation_type\n",
    "        self.combination_type = combination_type\n",
    "        self.normalize = normalize\n",
    "        self.hidden_units = hidden_units\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # FFN para preparar mensajes\n",
    "        self.ffn_prepare = create_ffn(hidden_units, dropout_rate, name=\"ffn_prepare\")\n",
    "        # Función de actualización: puede ser una GRU o una FFN\n",
    "        if self.combination_type == \"gru\":\n",
    "            self.update_fn = create_gru(hidden_units, dropout_rate)\n",
    "        else:\n",
    "            self.update_fn = create_ffn(hidden_units, dropout_rate, name=\"update_ffn\")\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        #We can implement the variable initialization here if necessary \n",
    "        super(GraphConvLayer, self).build(input_shape)\n",
    "\n",
    "    def prepare(self, node_representations, weights=None):\n",
    "        messages = self.ffn_prepare(node_representations)\n",
    "        if weights is not None:\n",
    "            messages = messages * tf.expand_dims(weights, -1)\n",
    "        return messages\n",
    "\n",
    "    def aggregate(self, node_indices, neighbour_messages, node_representations):\n",
    "        # As it can vary between images, we use the number of nodes dinamically\n",
    "        # node_indices shape is [num_edges].\n",
    "        # neighbour_messages shape: [num_edges, representation_dim].\n",
    "        # node_repesentations shape is [num_nodes, representation_dim]\n",
    "        num_nodes = tf.shape(node_representations)[0]\n",
    "        if self.aggregation_type == \"sum\":\n",
    "            aggregated_message = tf.math.unsorted_segment_sum(neighbour_messages, node_indices, num_segments=num_nodes)\n",
    "        elif self.aggregation_type == \"mean\":\n",
    "            aggregated_message = tf.math.unsorted_segment_mean(neighbour_messages, node_indices, num_segments=num_nodes)\n",
    "        elif self.aggregation_type == \"max\":\n",
    "            aggregated_message = tf.math.unsorted_segment_max(neighbour_messages, node_indices, num_segments=num_nodes)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid aggregation type: {self.aggregation_type}.\")\n",
    "        return aggregated_message\n",
    "\n",
    "    def update(self, node_representations, aggregated_messages):\n",
    "        # node_repesentations shape is [num_nodes, representation_dim].\n",
    "        # aggregated_messages shape is [num_nodes, representation_dim].\n",
    "        if self.combination_type == \"gru\":\n",
    "            h = tf.stack([node_representations, aggregated_messages], axis=1)\n",
    "        elif self.combination_type == \"concat\":\n",
    "            h = tf.concat([node_representations, aggregated_messages], axis=1)\n",
    "        elif self.combination_type == \"add\":\n",
    "            h = node_representations + aggregated_messages\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid combination type: {self.combination_type}.\")\n",
    "        node_embeddings = self.update_fn(h)\n",
    "        if self.combination_type == \"gru\":\n",
    "            # Seleccionamos la salida final de la secuencia GRU\n",
    "            node_embeddings = tf.unstack(node_embeddings, axis=1)[-1]\n",
    "        if self.normalize:\n",
    "            node_embeddings = tf.nn.l2_normalize(node_embeddings, axis=-1)\n",
    "        return node_embeddings\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Process the inputs to produce the node_embeddings.\n",
    "\n",
    "        inputs: a tuple of three elements: node_repesentations, edges, edge_weights.\n",
    "            -node_representations: tensor with shape (num_nodes,feature_dim)\n",
    "            -edges: tensor with shape (num_edges,2) \n",
    "            -edge_weights:with shape (num_edges,), as in our problem all the edges\n",
    "            have the same weight this tensor is going to be a ones array\n",
    "        Returns: node_embeddings of shape [num_nodes, representation_dim].\n",
    "        \"\"\"\n",
    "        node_representations, edges, edge_weights = inputs\n",
    "        # Divide the source and target indices\n",
    "        source_indexes = edges[:, 0]\n",
    "        target_indexes = edges[:, 1]\n",
    "        # Obtain the neighbour (target) representations\n",
    "        neighbour_representations = tf.gather(node_representations, target_indexes)\n",
    "        neighbour_messages = self.prepare(neighbour_representations, edge_weights)\n",
    "        aggregated_messages = self.aggregate(source_indexes, neighbour_messages, node_representations)\n",
    "        return self.update(node_representations, aggregated_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Node Classifier model \n",
    "\n",
    "class GNNNodeClassifier(tf.keras.Model):\n",
    "    def __init__(self, num_classes, hidden_units, aggregation_type=\"mean\",\n",
    "                 combination_type=\"concat\", dropout_rate=0.2, normalize=True, *args, **kwargs):\n",
    "        super(GNNNodeClassifier, self).__init__(*args, **kwargs)\n",
    "        # Preprocessing: transform the node features\n",
    "        self.preprocess = create_ffn(hidden_units, dropout_rate, name=\"preprocess\")\n",
    "        # Convolutional layers\n",
    "        self.conv1 = GraphConvLayer(hidden_units, dropout_rate, aggregation_type,\n",
    "                                    combination_type, normalize, name=\"graph_conv1\")\n",
    "        self.conv2 = GraphConvLayer(hidden_units, dropout_rate, aggregation_type,\n",
    "                                    combination_type, normalize, name=\"graph_conv2\")\n",
    "        # Postprocessing\n",
    "        self.postprocess = create_ffn(hidden_units, dropout_rate, name=\"postprocess\")\n",
    "        # Final layer that produces the logits for each node\n",
    "        self.compute_logits = layers.Dense(units=num_classes, name=\"logits\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Inputs should be a tuple of:\n",
    "        (node_features, edges, edge_weights, input_node_indices)\n",
    "        where:\n",
    "            - node_features: tensor with shape (batch_size, num_nodes, feature_dim)\n",
    "            - edges: tensor with shape (batch_size, num_edges, 2)\n",
    "            - edge_weights: tensor with shape (batch_size, num_edges)\n",
    "            - node_indices: tensor with shape (batch_size, num_nodes)\n",
    "        Each input corresponds to a graph/image\n",
    "\n",
    "        \"\"\"\n",
    "        node_features, edges, edge_weights, node_indices = inputs\n",
    "\n",
    "        # Function that processes a single graph\n",
    "        def process_graph(single_inputs):\n",
    "            nf, e, ew, ni = single_inputs  # nf: (num_nodes, feature_dim), e: (num_edges, 2), etc.\n",
    "            x = self.preprocess(nf)  # x: (num_nodes, hidden_dim)\n",
    "            x1 = self.conv1((x, e, ew))\n",
    "            x = x + x1  \n",
    "            x2 = self.conv2((x, e, ew))\n",
    "            x = x + x2  \n",
    "            x = self.postprocess(x)\n",
    "            # Obtain the representations for each node\n",
    "            node_emb = tf.gather(x, ni)\n",
    "            logits = self.compute_logits(node_emb)  # (num_nodes, num_classes)\n",
    "            return logits\n",
    "\n",
    "        # Apply tf.map_fn for processing each graph of the batch\n",
    "        outputs = tf.map_fn(process_graph, (node_features, edges, edge_weights, node_indices),\n",
    "                            fn_output_signature=tf.float32)\n",
    "        # outputs have shape:(batch_size, num_nodes, num_classes)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for extracting data from the dataframe and building the dataset\n",
    "def extract_graph_data(df, image_id):\n",
    "    \"\"\"\n",
    "    Extracts data of the graph for a given image\n",
    "      - Filters the rows with image_id.\n",
    "      - Uses columns 'x' and 'y' por Voronoi tessellation\n",
    "      - Extracts features for each node \n",
    "      - Label is the column 'activity'\n",
    "    \"\"\"\n",
    "    df_img = df[df['image_id'] == image_id].reset_index(drop=True)\n",
    "    num_nodes = df_img.shape[0]\n",
    "    \n",
    "    points = df_img[['x', 'y']].to_numpy()\n",
    "    vor = Voronoi(points)\n",
    "    # Obtains the edges (a pair of points) for the Voronoi tessellation\n",
    "    if len(vor.ridge_points) > 0:\n",
    "        edges = np.array(vor.ridge_points, dtype=np.int32)\n",
    "    else:\n",
    "        edges = np.empty((0, 2), dtype=np.int32)\n",
    "    num_edges = edges.shape[0]\n",
    "   \n",
    "    edge_weights = np.ones((num_edges,), dtype=np.float32)\n",
    "       \n",
    "    feature_cols = [col for col in df_img.columns if col not in ['image_id', 'x', 'y', 'activity','label','type']]\n",
    "    node_features = df_img[feature_cols].to_numpy().astype(np.float32)\n",
    "\n",
    "    labels = df_img['activity'].to_numpy().astype(np.int32)\n",
    "    # Modes indexes: just from 0 to num_nodes-1\n",
    "    node_indexes = np.arange(num_nodes, dtype=np.int32)\n",
    "    \n",
    "    return node_features, edges, edge_weights, node_indexes, labels\n",
    "\n",
    "#Creates a tf.data.Dataset from a dataframe\n",
    "def create_graph_dataset(df, batch_size, feature_dim):\n",
    "    image_ids = df['image_id'].unique()\n",
    "    \n",
    "    def gen():\n",
    "        for img_id in image_ids:\n",
    "            node_features, edges, edge_weights, node_indices, labels = extract_graph_data(df, img_id)\n",
    "            # Ensure that the shapes are correct:\n",
    "            node_features = np.reshape(node_features, (-1, feature_dim))\n",
    "            # edges with shape:(num_edges, 2)\n",
    "            edges = np.reshape(edges, (-1, 2))\n",
    "            edge_weights = np.reshape(edge_weights, (-1,))\n",
    "            node_indices = np.reshape(node_indices, (-1,))\n",
    "            labels = np.reshape(labels, (-1,))\n",
    "            yield (node_features, edges, edge_weights, node_indices), labels\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_signature=(\n",
    "            (\n",
    "                tf.TensorSpec(shape=(None, feature_dim), dtype=tf.float32),  # node_features\n",
    "                tf.TensorSpec(shape=(None, 2), dtype=tf.int32),              # edges\n",
    "                tf.TensorSpec(shape=(None,), dtype=tf.float32),              # edge_weights\n",
    "                tf.TensorSpec(shape=(None,), dtype=tf.int32),                # node_indices\n",
    "            ),\n",
    "            tf.TensorSpec(shape=(None,), dtype=tf.int32)  # labels\n",
    "        )\n",
    "    )\n",
    "    # Use padded_batch para handling graphs with a varying number of edges\n",
    "    dataset = dataset.padded_batch(\n",
    "        batch_size,\n",
    "        padded_shapes=(\n",
    "            (\n",
    "                tf.TensorShape([None, feature_dim]),  # node_features\n",
    "                tf.TensorShape([None, 2]),              # edges\n",
    "                tf.TensorShape([None]),                # edge_weights\n",
    "                tf.TensorShape([None]),                # node_indices\n",
    "            ),\n",
    "            tf.TensorShape([None])  # labels\n",
    "        ),\n",
    "        padding_values=(\n",
    "            (\n",
    "                tf.constant(0, dtype=tf.float32),\n",
    "                tf.constant(0, dtype=tf.int32),\n",
    "                tf.constant(0, dtype=tf.float32),\n",
    "                tf.constant(0, dtype=tf.int32),\n",
    "            ),\n",
    "            tf.constant(-1, dtype=tf.int32)\n",
    "        )\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the input data\n",
    "density=0.008\n",
    "fa=100\n",
    "input_file=f'phia{density}/traj_phia{density}-T05-Fa{fa}-tau1.dat'\n",
    "df=pd.read_csv(input_file, sep='\\s+',names=[\"label\", \"type\", \"x\", \"y\"])\n",
    "cols_names=['area', 'perimeter', 'neighbours', 'max neighbour distance',\n",
    "       'min neighbour distance', 'max vertices distance',\n",
    "       'min vertices distance', 'max vertices-point distance',\n",
    "       'min vertices-point distance', 'distance to center', 'activity',\n",
    "       'particle type']\n",
    "input_file2=f\"phia{density}/particles-features-{density}-Fa{fa}.txt\"\n",
    "df2=pd.read_csv(input_file2, sep='\\s+',names=cols_names)\n",
    "\n",
    "#Create a dataframe that includes both, the voronoi features and the particle positions\n",
    "df=df[0:2_000_000].join(df2)\n",
    "df['image_id']=np.floor(df.index/1000) #Add a column with the id of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in df.columns if col not in ['image_id', 'x', 'y', 'activity','label','type']]\n",
    "feature_dim = len(feature_cols)\n",
    "\n",
    "# Model parameters\n",
    "num_classes = 2       \n",
    "hidden_units = [64, 64]\n",
    "dropout_rate = 0.2\n",
    "aggregation_type = \"mean\"\n",
    "combination_type = \"concat\"\n",
    "normalize = True\n",
    "batch_size = 1  \n",
    "\n",
    "images_ids=df['image_id'].unique()\n",
    "train_images_ids,test_images_ids=train_test_split(images_ids,random_state=50,test_size=0.2)\n",
    "train_df=df[df['image_id'].isin(train_images_ids)].reset_index(drop=True)\n",
    "test_df=df[df['image_id'].isin(test_images_ids)].reset_index(drop=True)\n",
    "\n",
    "# Create training and testing datasets\n",
    "train_dataset = create_graph_dataset(train_df, batch_size, feature_dim)\n",
    "test_dataset = create_graph_dataset(test_df, batch_size, feature_dim)\n",
    "\n",
    "# Instance and compile the GNN model\n",
    "model = GNNNodeClassifier(num_classes, hidden_units, aggregation_type, combination_type, dropout_rate, normalize)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9941 - loss: 0.0215\n",
      "Epoch 2/10\n",
      "\u001b[1m   9/1600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.9943 - loss: 0.0193"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9940 - loss: 0.0215\n",
      "Epoch 3/10\n",
      "\u001b[1m   9/1600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9940 - loss: 0.0194"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9941 - loss: 0.0214\n",
      "Epoch 4/10\n",
      "\u001b[1m   7/1600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.9942 - loss: 0.0193"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9941 - loss: 0.0213\n",
      "Epoch 5/10\n",
      "\u001b[1m   9/1600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9943 - loss: 0.0198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9941 - loss: 0.0211\n",
      "Epoch 6/10\n",
      "\u001b[1m   9/1600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9945 - loss: 0.0197"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9942 - loss: 0.0210\n",
      "Epoch 7/10\n",
      "\u001b[1m   9/1600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.9947 - loss: 0.0192"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9943 - loss: 0.0206\n",
      "Epoch 8/10\n",
      "\u001b[1m   9/1600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.9945 - loss: 0.0196"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9943 - loss: 0.0205\n",
      "Epoch 9/10\n",
      "\u001b[1m   9/1600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9943 - loss: 0.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9944 - loss: 0.0203\n",
      "Epoch 10/10\n",
      "\u001b[1m   9/1600\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9954 - loss: 0.0188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9944 - loss: 0.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x244daa288e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(train_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9937 - loss: 0.0231\n",
      "0.9935999512672424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "accuracy=model.evaluate(test_dataset)\n",
    "print(accuracy[1])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
